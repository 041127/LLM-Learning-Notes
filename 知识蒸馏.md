# 知识蒸馏

## 1.概述

![image-20250711140409988](知识蒸馏.assets/image-20250711140409988.png)

## 2.相关概念

- Soft Label：包含了更多“知识”和“信息’，即像谁，不像谁，有多像，有多不像
    特别是非正确类别概率的相对大小（驴和车）

- 蒸馏温度T：T越高，soft label就更soft，突出了非正确类别概率之间的相对大小之间的差距。T过小，两极分化严重，T过大，各类别间没有显著差距![image-20250711142453583](知识蒸馏.assets/image-20250711142453583.png)

    ![image-20250711142917693](知识蒸馏.assets/image-20250711142917693.png)

## 3.知识蒸馏过程

- 利用soft targets

![image-20250711154012458](知识蒸馏.assets/image-20250711154012458.png)

给定Input，教师网络输出T=t对应的soft labels,学生网络输出T=t对应的soft predictions,和T=1对应的hard predictions,soft predictions与soft labels对比输出soft loss，hard predictions与hard labels对比输出hard loss，总的loss为soft loss和hard loss的权重和

- 利用label smoothing

![image-20250711160631064](知识蒸馏.assets/image-20250711160631064.png)



## 4.知识蒸馏的应用场景

- 模型压缩
- 优化训练，防止过拟合（soft targets的作用）
- 无限大、无监督数据集的数据挖掘
- 少样本、零样本学习

## 5.知识蒸馏的背后机理

让学生网络通过模仿教师网络从而得到一个收敛后更接近于教师网络的网络，性能比自学的收敛网络更好，因为更接近于教师网络

## 6.知识蒸馏发展趋势

- 教学相长
- 助教，多个老师、同学
- 知识的表示（结果、中间层还是层与层的关系等等）![image-20250711162241435](知识蒸馏.assets/image-20250711162241435.png)、数据集蒸馏、对比学习
- 多模态、知识图谱、预训练大模型的知识蒸馏

## 7.工具

![image-20250711221641721](知识蒸馏.assets/image-20250711221641721.png)

## 8.相关论文

![image-20250711221720607](知识蒸馏.assets/image-20250711221720607.png)

![image-20250711221737088](知识蒸馏.assets/image-20250711221737088.png)

![image-20250711221757702](知识蒸馏.assets/image-20250711221757702-1752243478975-1.png)

