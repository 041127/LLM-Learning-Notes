| **分类**           | **标识**      | **含义**                                                     | **示例（模型名称）**           |
| :----------------- | ------------- | ------------------------------------------------------------ | ------------------------------ |
| **功能与任务类型** | `-Base`       | 基础模型，未经过特定任务微调，提供原始能力（用于二次开发）。 | Qwen3-14B-Base                 |
|                    | `-Chat`       | 对话优化模型，支持交互式聊天、问答，针对对话生成任务微调（主要见于早期模型，目前已经可以被 Instruct 模型替代）。 | DeepSeek-LLM-7B-Chat           |
|                    | `-Instruct`   | 指令微调模型，擅长遵循具体任务指令（推理、生成、翻译等）。   | Qwen3-0.6B-Instruct            |
|                    | `-Distill`    | 知识蒸馏模型，通过蒸馏技术压缩，模型更小、推理更高效。       | DeepSeek-R1-1.5B-Distill       |
|                    | `-Math`       | 专注数学推理任务，优化数值计算、公式解析、逻辑证明等能力。   | DeepSeek-Math-7B-Instruct      |
|                    | `-Coder`      | 针对代码生成、编程任务优化，支持代码补全、漏洞检测、算法实现等。 | DeepSeek-Coder-V2-16B          |
| **多模态**         | `-VL`         | 视觉-语言多模态（Vision-Language），支持图文联合输入输出。   | Kimi-VL-A3B-Instruct           |
|                    | `-Video`      | 视频多模态模型，结合视频帧与文本进行交互。                   | LLaVA-NeXT-Video-7B-Chat       |
|                    | `-Audio`      | 支持音频输入，如语音识别（ASR）。                            | Qwen2-Audio-7B                 |
| **技术特性与优化** | `-Int8/-Int4` | 权重量化为8位/4位，降低显存占用，提升推理速度（适合低资源设备）。 | Qwen2-VL-2B-Instruct-GPTQ-Int8 |
|                    | `-AWQ/-GPTQ`  | 特定量化技术（自适应权重/GPTQ量化），优化低精度下的模型性能。 | Qwen2.5-VL-72B-Instruct-AWQ    |
|                    | `-MoE`        | 混合专家模型（Mixture of Experts），包含多个专用模块处理复杂任务。 | DeepSeek-MoE-16B-Chat          |
|                    | `-RL`         | 使用强化学习（Reinforcement Learning）优化，提升对话质量或任务响应。 | MiMo-7B-Instruct-RL            |
| **版本与变体标识** | `-v0.1/-v0.2` | 模型版本号，标识开发阶段（alpha/beta/正式版）。              | Mistral-7B-v0.1                |
|                    | `-Pure`       | 纯净版模型，去除领域数据或保留原始能力，避免预训练偏差。     | Index-1.9B-Base                |
|                    | `-Character`  | 角色对话模型，专注角色扮演或特定人设（如虚拟助手、动漫角色）。 | Index-1.9B-Character-Chat      |
|                    | `-Long-Chat`  | 支持长上下文对话（通常>4k tokens），处理超长输入输出。       | Orion-14B-Long-Chat            |
| **领域与应用标识** | `-RAG`        | 检索增强生成模型，结合外部知识库检索与生成能力。             | Orion-14B-RAG-Chat             |
|                    | `-Chinese`    | 中文优化版本，支持中文分词、方言、拼音纠错等本土化能力。     | Llama-3-70B-Chinese-Chat       |
|                    | `-MT`         | 机器翻译专用模型，支持多语言翻译任务（如中英、英日互译）。   | BLOOMZ-7B1-mt                  |

