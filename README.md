# 🧠 LLM-Learning-Notes

这是一个持续更新的大模型（LLM）学习笔记仓库，涵盖理论基础、模型微调、工程部署、训练实践、工具教程等内容。适用于希望深入理解大模型原理并进行实战训练的学习者和开发者。

## 📚 内容结构

### 📖 理论部分（theory/）
- `AI基础理论.md`：人工智能与机器学习的基础框架
- `机器学习知识.md`：从监督学习到深度学习核心概念
- `Pytorch深度学习教程.md`：模型构建与训练
- `LoRA.md`：参数高效微调原理与应用
- `DPO.md`：偏好优化（Direct Preference Optimization）方法详解
- `知识蒸馏.md`：模型压缩与 teacher-student 学习机制

### 🛠 工具使用（tools/）
- `hugging_face.md`：使用 Transformers 库进行模型加载与训练
- `Wandb使用.md`：实验追踪与可视化
- `tmux.md`：Linux 多任务训练环境配置

### 🤖 模型解析（models/）
- `模型名称的含义.md`：大模型命名规则与结构解析
- `qwen.md`：Qwen 模型结构与使用说明
- `LLaMa Factory微调.md`：LLaMa 模型微调实录

### 🔬 实战教程（labs/）
- `lab00`：训练模型所需的前置知识与准备工作
- `lab01`：搭建 GPU 环境 + 使用 Axolotl 微调大模型

### 📊 数据处理与分析（data/）
- `数据分析.md`：训练前数据预处理和质量分析方法

### 💼 面试准备（interviews/）
- `LLM面试问题.md`：大模型相关技术岗常见面试问题整理

## 🧩 未来计划（To-do）
- [ ] 添加 RAG（检索增强生成）笔记
- [ ] 整理 RLHF / PPO 相关知识
- [ ] 整合 Eval / Leaderboard 实战经验

## 📝 License
MIT License

---

欢迎提 issue、PR 或交流探讨。如果你也在学习大模型训练、微调、部署，欢迎一起交流！
