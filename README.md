# 🧠 LLM-Learning-Notes

这是一个持续更新的大模型（LLM）学习笔记仓库，涵盖了从理论基础到模型微调、数据处理、训练实践等方面的内容。适用于想要深入理解大模型原理并进行实战训练的学习者和开发者。

## 📚 内容结构

### 📖 理论部分（theory/）

* `AI基础理论.md`：人工智能与机器学习的基础框架。
* `Bert.docx`：BERT模型及其应用介绍。
* `Pytorch深度学习教程.md`：基于PyTorch的深度学习模型构建与训练。
* `DPO.md`：Direct Preference Optimization（DPO）方法解析。
* `PPO.md`：Proximal Policy Optimization（PPO）算法详解。
* `Tokenizer说明.md`：Tokenizer的工作原理与应用。

### 🤖 模型解析（models/）

* `Transformer.docx`：Transformer模型的核心思想与实现。
* `模型名称的含义.md`：大模型命名规则与结构解析。

### 🔬 实战教程（labs/）

* `lab00-训练模型前置知识.md`：为训练大模型所需的前置知识与准备工作。
* `lab01-GPU环境搭建和基于axolotl训练大模型.md`：环境搭建与使用Axolotl微调大模型。
* `unsloth+LoRA微调全流程.md`：使用Unsloth与LoRA进行模型微调的完整流程。

### 📊 数据处理与分析（data/）

* `数据分析.md`：数据处理与分析方法，特别是用于大模型训练的数据预处理。
* `python&数据分析.docx`：Python与数据分析工具在大模型训练中的结合应用。

## 🧩 未来计划（To-do）

* [ ] 添加RAG（检索增强生成）笔记。
* [ ] 整理RLHF / PPO相关知识。
* [ ] 整合Eval / Leaderboard实战经验。

## 📝 License

MIT License

---

欢迎提issue、PR或进行讨论交流。如果你也在学习大模型训练、微调与部署，欢迎加入交流！
